"use strict";

function error(err) {
    return logger(err.message);
}

function writeMetadata(collection, metadata, next) {
    collection.indexes(function(err, indexes) {
        return err ? (error(err), next()) : (fs.writeFileSync(metadata + collection.collectionName, JSON.stringify(indexes), {
            encoding: "utf8"
        }), void next());
    });
}

function makeDir(path, next) {
    return fs.stat(path, function(err, stats) {
        return err && "ENOENT" === err.code ? (logger("make dir at " + path), fs.mkdir(path, function(err) {
            return next(err, path);
        })) : stats && stats.isDirectory() === !1 ? (logger("unlink file at " + path), fs.unlink(path, function() {
            return logger("make dir at " + path), fs.mkdir(path, function(err) {
                return next(err, path);
            });
        })) : next(null, path);
    });
}

function rmDir(path, next) {
    fs.readdirSync(path).forEach(function(first) {
        var database = path + first;
        if (fs.statSync(database).isDirectory() !== !1) {
            var metadata = "", collections = fs.readdirSync(database);
            fs.existsSync(database + "/.metadata") === !0 && (metadata = database + "/.metadata/", 
            delete collections[collections.indexOf(".metadata")]), collections.forEach(function(second) {
                var collection = database + "/" + second;
                fs.statSync(collection).isDirectory() !== !1 && (fs.readdirSync(collection).forEach(function(third) {
                    var document = collection + "/" + third;
                    next && next(null, document), fs.unlinkSync(document);
                }), "" !== metadata && fs.unlinkSync(metadata + second), fs.rmdirSync(collection));
            }), "" !== metadata && fs.rmdirSync(metadata), fs.rmdirSync(database);
        }
    });
}

function toJson(docs, collectionPath, next) {
    var last = docs.length, index = 0;
    return 1 > last ? next() : void docs.forEach(function(doc) {
        return fs.writeFileSync(collectionPath + doc._id + ".json", JSON.stringify(doc), {
            encoding: "utf8"
        }), last === ++index ? next() : null;
    });
}

function toBson(docs, collectionPath, next) {
    var last = docs.length, index = 0;
    return 1 > last ? next() : void docs.forEach(function(doc) {
        return fs.writeFileSync(collectionPath + doc._id + ".bson", BSON.serialize(doc), {
            encoding: null
        }), last === ++index ? next() : null;
    });
}

function allCollections(db, name, query, metadata, parser, next) {
    db.collections(function(err, collections) {
        if (err) return error(err);
        var last = collections.length, index = 0;
        return 1 > last ? next(null) : void collections.forEach(function(collection) {
            return /^system./.test(collection.collectionName) === !0 ? last === ++index ? next(null) : null : (logger("select collection " + collection.collectionName), 
            void makeDir(name + collection.collectionName + "/", function(err, name) {
                meta(collection, metadata, function() {
                    collection.find(query).toArray(function(err, docs) {
                        return err ? last === ++index ? next(err) : error(err) : void parser(docs, name, function(err) {
                            return err ? last === ++index ? next(err) : error(err) : last === ++index ? next(null) : null;
                        });
                    });
                });
            }));
        });
    });
}

function someCollections(db, name, query, metadata, parser, next, collections) {
    var last = collections.length, index = 0;
    return 1 > last ? next(null) : void collections.forEach(function(collection) {
        db.collection(collection, function(err, collection) {
            return logger("select collection " + collection.collectionName), err ? last === ++index ? next(err) : error(err) : void makeDir(name + collection.collectionName + "/", function(err, name) {
                meta(collection, metadata, function() {
                    collection.find(query).toArray(function(err, docs) {
                        return err ? last === ++index ? next(err) : error(err) : void parser(docs, name, function(err) {
                            return err ? last === ++index ? next(err) : error(err) : last === ++index ? next(null) : null;
                        });
                    });
                });
            });
        });
    });
}

function wrapper(my) {
    function callback() {
        logger("backup stop"), null !== my.callback && (logger("callback run"), my.callback());
    }
    var parser;
    if ("function" == typeof my.parser) parser = my.parser; else switch (my.parser) {
      case "bson":
        BSON = require("bson"), BSON = new BSON.BSONPure.BSON(), parser = toBson;
        break;

      case "json":
        parser = toJson;
        break;

      default:
        throw new Error("missing parser option");
    }
    var discriminator = allCollections;
    if (null !== my.collections && (discriminator = someCollections), null === my.logger) logger = function() {}; else {
        logger = require("logger-request")({
            filename: my.logger,
            standalone: !0,
            winston: {
                logger: "_mongo_r" + my.logger,
                level: "info",
                json: !1
            }
        }), logger("backup start");
        var log = require("mongodb").Logger;
        log.setLevel("info"), log.setCurrentLogger(function(msg) {
            logger(msg);
        });
    }
    var metadata = "";
    meta = my.metadata === !0 ? writeMetadata : function(a, b, c) {
        return c();
    }, require("mongodb").MongoClient.connect(my.uri, my.options, function(err, db) {
        if (logger("db open"), err) return error(err);
        var root = null === my.tar ? my.root : my.dir;
        makeDir(root, function(err, name) {
            makeDir(name + db.databaseName + "/", function(err, name) {
                var go = function() {
                    discriminator(db, name, my.query, metadata, parser, function() {
                        return logger("db close"), db.close(), my.tar ? makeDir(my.root, function(err, name) {
                            var dest;
                            my.stream ? (logger("send tar file to stream"), dest = my.stream) : (logger("make tar file at " + name + my.tar), 
                            dest = fs.createWriteStream(name + my.tar));
                            var packer = require("tar").Pack().on("error", error).on("end", function() {
                                return rmDir(root), callback();
                            });
                            return require("fstream").Reader({
                                path: root + db.databaseName,
                                type: "Directory"
                            }).on("error", error).pipe(packer).pipe(dest);
                        }) : callback();
                    }, my.collections);
                };
                my.metadata === !1 ? go() : (metadata = name + ".metadata/", makeDir(metadata, go));
            });
        });
    });
}

function backup(options) {
    var resolve = require("path").resolve, opt = options || Object.create(null);
    if (!opt.uri) throw new Error("missing uri option");
    if (!opt.stream) {
        if (!opt.root) throw new Error("missing root option");
        if (fs.existsSync(opt.root) && !fs.statSync(opt.root).isDirectory()) throw new Error("root option is not a directory");
    }
    var my = {
        dir: __dirname + "/dump/",
        uri: String(opt.uri),
        root: resolve(String(opt.root || "")) + "/",
        stream: opt.stream || null,
        parser: opt.parser || "bson",
        collections: Array.isArray(opt.collections) ? opt.collections : null,
        callback: "function" == typeof opt.callback ? opt.callback : null,
        tar: "string" == typeof opt.tar ? opt.tar : null,
        query: "object" == typeof opt.query ? opt.query : {},
        logger: "string" == typeof opt.logger ? resolve(opt.logger) : null,
        options: "object" == typeof opt.options ? opt.options : {},
        metadata: Boolean(opt.metadata)
    };
    return my.stream && (my.tar = !0), wrapper(my);
}

var fs = require("fs"), BSON, logger, meta;

module.exports = backup;
